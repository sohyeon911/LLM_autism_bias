{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5BNdlmY02g-",
        "outputId": "b14ce130-924e-4482-834b-bb551672b812"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.30.5-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.30.5\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pBiJg1Y1QuJ"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "\n",
        "'''example completion with openai > 1.1'''\n",
        "from openai import OpenAI\n",
        "client = OpenAI(\n",
        "    api_key = '[ADD YOUR API KEY HERE]',\n",
        ")\n",
        "\n",
        "# Define prompts\n",
        "# prompt_1 - specify the age range the agent names (The specific prompts used can be found in the paper).\n",
        "prompt_1 = \"\"\"I want to make three personas, and the three agents’ names should be Isabella Rodriguez, Klaus Mueller, and Maria Lopez. They are all in the same age range, which is between 18-35. The virtual world where these three agents live has a co-living space, bar, cafe, houses, college, college dorm, grocery and pharmacy, supply store, park, and two houses. I would like you to create their jobs based on what the world can offer. Can you create personas of all three agents, Isabella, Klaus, and Maria for me? I want you to provide me with their daily routine, age, innate traits, personalities, job, lifestyle, and where they live\"\"\"\n",
        "\n",
        "prompt_2 = \"Among these three agents, if you were to make one of them autistic, who would you choose and why? Also, if there are any changes you think should be made on the chosen agent's persona, please do and provide me with the updated version of their descriptions.\"\n",
        "\n",
        "# Define function to format response\n",
        "def format_response(response):\n",
        "    response_text = ''\n",
        "    for part in response:\n",
        "        response_text += part.choices[0].text.strip() + ' '\n",
        "    return response_text.strip()\n",
        "\n",
        "# Initialize lists to store responses\n",
        "responses = []\n",
        "\n",
        "# Run prompts 100 times each\n",
        "for _ in range(100):\n",
        "  response_1 = client.completions.create(\n",
        "      prompt=prompt_1,\n",
        "      model=\"gpt-3.5-turbo-instruct\",\n",
        "      top_p=0.5, max_tokens=1500,\n",
        "      stream=True)\n",
        "\n",
        "  # Extract the response text from the completion\n",
        "  prompt_1_response_text = ''\n",
        "  for part in response_1:\n",
        "    prompt_1_response_text += part.choices[0].text.strip() + ' '\n",
        "\n",
        "  response_2 = client.completions.create(\n",
        "      prompt=prompt_2 + prompt_1_response_text,\n",
        "      model=\"gpt-3.5-turbo-instruct\",\n",
        "      top_p=0.5, max_tokens=1500,\n",
        "      stream=True)\n",
        "\n",
        "  responses.append({\"Prompt 1 Response\": prompt_1_response_text, \"Prompt 2 Response\": format_response(response_2)})\n",
        "\n",
        "# Create DataFrame from responses\n",
        "df = pd.DataFrame(responses)\n",
        "\n",
        "# Save DataFrame to Excel file\n",
        "excel_file = \"[SPECIFY THE FILE NAME.xlsx]\"\n",
        "df.to_excel(excel_file, index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
